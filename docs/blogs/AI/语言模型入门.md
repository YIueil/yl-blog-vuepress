---
date: 2025-01-30 19:56:03
pageClass: blue-archive
tags:
  - ChatGPT
categories:
  - AI
---

# 语言模型入门
> 使用 ollama + deepseek + docker + Open WebUI 实现本地部署的对话模型。

## 1 ollama安装配置
下载适用于电脑软件平台的ollama安装包后，进行安装。

打开终端
- 执行`Ollama -v`，将输出安装的Ollama版本号。
- 执行`Ollama list model`列举可运行的模型，此时应当是没有任何输出的，因为还没有下载和导入如题的语言模型文件。

### 两种DeepSeek模型下载方式
**1.1 直接通过Ollama进行下载（方式一）**
选择适合自己跑的模型，数字越大需要的硬件性能越高：

| 模型参数 | Windows配置要求                                               | Mac配置要求                                         | 适用场景          |
| ---- | --------------------------------------------------------- | ----------------------------------------------- | ------------- |
| 1.5B | - RAM: 4GB<br>- GPU: 集成显卡 (如GTX 1050) 或现代CPU<br>- 存储: 5GB | - 内存: 8GB (统一内存)<br>- 芯片: M1/M2/M3<br>- 存储: 5GB | 简单文本生成/基础代码补全 |
| 7B   | - RAM: 8-10GB<br>- GPU: GTX 1660 (4-bit量化)<br>- 存储: 8GB   | - 内存: 16GB<br>- 芯片: M2 Pro/M3<br>- 存储: 8GB      | 中等复杂度问答/代码调试  |
| 8B   | - RAM: 12GB<br>- GPU: RTX 3060 (8GB VRAM)<br>- 存储: 10GB   | - 内存: 24GB<br>- 芯片: M2 Max<br>- 存储: 10GB        | 多轮对话/文档分析     |
| 14B  | - RAM: 24GB<br>- GPU: RTX 3090 (24GB VRAM)<br>- 存储: 20GB  | - 内存: 32GB<br>- 芯片: M3 Max<br>- 存储: 20GB        | 复杂推理/技术文档生成   |
| 32B  | - RAM: 48GB<br>- GPU: RTX 4090 (4-bit量化)<br>- 存储: 40GB    | - 内存: 64GB<br>- 芯片: M3 Ultra<br>- 存储: 40GB      | 科研计算/大规模数据处理  |
| 70B  | - RAM: 64GB<br>- GPU: 双RTX 4090 (NVLINK)<br>- 存储: 80GB    | - 内存: 128GB (需外接显存坞)<br>- 存储: 80GB              | 企业级AI服务/多模态处理 |
| 671B | - RAM: 256GB+<br>- GPU: 8xH100 (通过NVLINK连接)<br>- 存储: 1TB+ | 暂不支持                                            | 超大规模云端推理      |

![1mOxw3pSKTNzCcg.png](https://s2.loli.net/2025/02/05/1mOxw3pSKTNzCcg.png)

选好后终端执行命令`Ollama run deepseek-r1:1.5b`，我这里选择1.5b，做简单的翻译功能。

**1.2 在[https://huggingface.co/](https://huggingface.co/)进行下载（方式二）**
待完善

### 运行模型
1. 终端执行命令`Ollama list`可以查看已经存在的模型。
2. 终端执行命令`Ollama run <模型名称>`，运行对应的模型。如果模型不存在，则会自动进行对应模型的下载。

此时已经可以在终端进行对话，但是不方便会话管理。
![pq6rNBTfhUkJ4dg.png](https://s2.loli.net/2025/02/06/pq6rNBTfhUkJ4dg.png)
## 2 Open WebUI 安装
官网：[🏡Open WebUI](https://docs.openwebui.com/)
使用Open WebUI图形化页面来管理模型对话的记录。
使用Docker进行安装：`docker run -d -p 3000:8080 --add-host=host.docker.internal:host-gateway -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main`
此时打开自己docker容器应用对应的端口，即可在浏览器可视化页面中进行对话的管理：
![kMrOBGCpa3uwo1T.png](https://s2.loli.net/2025/02/05/kMrOBGCpa3uwo1T.png)